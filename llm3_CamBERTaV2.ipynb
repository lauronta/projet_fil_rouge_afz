{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import random as rd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "# from transformers import AutoTokenizer\n",
    "from transformers import BertForMaskedLM, AutoTokenizer, AutoModelForMaskedLM\n",
    "from tokenizers.models import WordPiece\n",
    "from tokenizers.trainers import WordPieceTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Détermination du Path\n",
    "\n",
    "DATASET_PATH = Path(\"./data/text\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des données textuelles\n",
    "\n",
    "VOC_SIZE = 1000\n",
    "\n",
    "def load_data(datapath, max_size=None):\n",
    "    texts_files = list(datapath.glob(\"*.txt\"))\n",
    "    texts = []  \n",
    "    for files in texts_files:\n",
    "        with open(files, \"r\", encoding='utf8') as files:\n",
    "            text = files.readlines()\n",
    "            texts += text\n",
    "    texts = list(set(texts))\n",
    "    \n",
    "    return texts\n",
    "\n",
    "texts = load_data(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForMaskedLM were not initialized from the model checkpoint at almanach/camembertav2-base and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'En', '##si', '##lages', 'En', '##si', '##lage', 'de', 'pra', '##ir', '##ie', ',', 'ray', '-', 'gras', '##s', 'anglais', ',', 'ray', '-', 'gras', '##s', 'italien', ',', '50', '/', '50', 'En', '##si', '##lage', 'de', 'partie', 'aérienne', 'de', 'ray', '-', 'gras', '##s', 'anglais', 'et', 'italien', '(', 'Lo', '##li', '##um', 'per', '##enne', 'L', '.', 'et', 'Lo', '##li', '##um', 'multif', '##lor', '##um', 'Lam', '.)', 'en', 'proportions', 'égales', '.', '\\n', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "# Chargement du modèle CamemBERTav2 et tokenisation du texte\n",
    "\n",
    "model_checkpoint = \"almanach/camembertav2-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_checkpoint)\n",
    "\n",
    "inputs = tokenizer(texts, return_tensors='pt', max_length=100, \n",
    "                   truncation=True, padding='max_length')\n",
    "\n",
    "inputs['labels'] = inputs.input_ids.detach().clone()\n",
    "\n",
    "print(inputs.tokens(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données pour le Modèle de language maskey\n",
    "\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102) * (inputs.input_ids != 0)\n",
    "\n",
    "inputs.input_ids[mask_arr] = 103\n",
    "\n",
    "sample_idx = [i for i in range(len(inputs.input_ids))]\n",
    "\n",
    "shuffled_sample_idx = rd.sample(sample_idx, len(sample_idx))\n",
    "\n",
    "train_idx = shuffled_sample_idx[:int(0.70*len(shuffled_sample_idx))]\n",
    "val_idx = shuffled_sample_idx[int(0.70*len(shuffled_sample_idx)):int(0.85*len(shuffled_sample_idx))]\n",
    "test_idx = shuffled_sample_idx[int(0.85*len(shuffled_sample_idx)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation du dataset\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, idx):\n",
    "        self.encodings = encodings\n",
    "        self.idx = idx\n",
    "        self.encodings = {key: [val[i] for i in self.idx] for key, val in self.encodings.items()}\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "dataset_train = CustomDataset(inputs, train_idx)\n",
    "dataset_val = CustomDataset(inputs, val_idx)\n",
    "dataset_test = CustomDataset(inputs, test_idx)\n",
    "\n",
    "train_dataloaded = torch.utils.data.DataLoader(dataset_train, batch_size=16, shuffle=True)\n",
    "val_dataloaded = torch.utils.data.DataLoader(dataset_val, batch_size=16, shuffle=True)\n",
    "test_dataloaded = torch.utils.data.DataLoader(dataset_test, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class MLM_model(nn.Module):\n",
    "#    def __init__(self, model):\n",
    "#        super(MLM_model, self).__init__()\n",
    "#        self.history = {\"epochs\":[], \"test\":[]}\n",
    "#        self.model = model\n",
    "    \n",
    "#    def parameters(self):\n",
    "#        return self.model.parameters()\n",
    "\n",
    "#    def forward(self, x, attention_mask, labels):\n",
    "#        return self.model(x, attention_mask, labels)\n",
    "    \n",
    "#    def train_log(self, train_batch_losses, val_batch_losses, train_loss, validation_loss):\n",
    "#        self.history[\"epochs\"].append({\"train_batch_losses\":train_batch_losses, \n",
    "#                                \"val_batch_losses\":val_batch_losses, \n",
    "#                                \"train_loss\":train_loss, \n",
    "#                                \"validation_loss\":validation_loss})\n",
    "    \n",
    "#    def test_log(self, test_batch_losses, test_loss):\n",
    "#        self.history[\"test\"].append({\"test_batch_losses\":test_batch_losses,\n",
    "#                                \"test_loss\":test_loss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Définition du device \n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#model = MLM_model(model)\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprentissage\n",
    "\n",
    "def train_step(module, batch, batch_idx, optimizer):\n",
    "    module.train(True)\n",
    "    \n",
    "    inputs_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['labels'].to(device)\n",
    "    \n",
    "    outputs = module(inputs_ids, attention_mask, labels=labels)\n",
    "    \n",
    "    loss = outputs.loss\n",
    "    print(f\"\\n\\033[1;37mBatch loss {batch_idx+1} : {loss.item()}\")\n",
    "    loss.backward()\n",
    "    \n",
    "    torch.nn.utils.clip_grad_norm_(module.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return module, loss\n",
    "\n",
    "def eval_step(module, batch, batch_idx, optimizer=None, training=True):\n",
    "    if training == False :\n",
    "            module.to('cpu')\n",
    "            \n",
    "    with torch.no_grad():\n",
    "            \n",
    "        inputs_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "    \n",
    "        outputs = module(inputs_ids, attention_mask, labels=labels)\n",
    "    \n",
    "        loss = outputs.loss\n",
    "         \n",
    "        if training:\n",
    "            print(f\"\\n\\033[1;32mValidation Batch loss {batch_idx+1} : {loss.item()}\")\n",
    "            return module, loss\n",
    "        else:\n",
    "            print(f\"\\n\\033[1;32mTest Batch loss {batch_idx+1} : {loss.item()}\")\n",
    "            return module, loss, outputs, labels\n",
    "\n",
    "def train_loop(module, EPOCHS, train_dataset, val_dataset, optimizer, lr_scheduler=None):\n",
    "    for epoch in range(EPOCHS):\n",
    "        deb=time.time()\n",
    "        \n",
    "        module.train(True)\n",
    "        \n",
    "        train_batch_losses = []\n",
    "        for batch_idx in range(len(train_dataset)):\n",
    "            batch = next(iter(train_dataset))\n",
    "            module, loss = train_step(module, batch, batch_idx, optimizer)\n",
    "            train_batch_losses.append(loss.item())\n",
    "            \n",
    "        if lr_scheduler is not None:\n",
    "          lr_scheduler.step()\n",
    "        train_loss = np.mean(train_batch_losses)\n",
    "\n",
    "        module.train(False)\n",
    "        val_batch_losses = []\n",
    "        for batch_idx in range(len(val_dataset)):\n",
    "            batch = next(iter(val_dataset))\n",
    "            module, loss = eval_step(module, batch, batch_idx)\n",
    "            val_batch_losses.append(loss.item())\n",
    "        val_loss = np.mean(val_batch_losses)\n",
    "\n",
    "#        module.train_log(train_batch_losses, val_batch_losses, train_loss, val_loss)\n",
    "        print(f\"\\n\\033[1;33mEpoch {epoch+1} :\\n\\033[1;37mTraining Loss : {train_loss}\")\n",
    "        print(f\"\\033[1;32mValidation Loss : {val_loss}\")\n",
    "        print(f\"\\033[1;31mDurée epoch : {time.time()-deb} secondes\")\n",
    "    return module\n",
    "\n",
    "def evaluate(module, test_dataset):\n",
    "    module.train(False)\n",
    "    test_batch_losses = []\n",
    "    predictions = []\n",
    "    true_targets = []\n",
    "    for batch_idx in range(len(test_dataset)):\n",
    "        batch = next(iter(test_dataset))\n",
    "        module, loss, outputs, labels = eval_step(module, batch, batch_idx, training=False)\n",
    "\n",
    "        test_batch_losses.append(loss.item())\n",
    "        predictions.append(outputs)\n",
    "        true_targets.append(labels)\n",
    "\n",
    "    test_loss = np.mean(test_batch_losses)\n",
    "#    module.test_log(test_batch_losses, test_loss)\n",
    "    print(f\"\\nTest Loss : {test_loss}\")\n",
    "    return predictions, true_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rapha\\AppData\\Local\\Temp\\ipykernel_41320\\3187914882.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key : torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;37mBatch loss 1 : 17.32294273376465\n",
      "\n",
      "\u001b[1;37mBatch loss 2 : 15.318177223205566\n",
      "\n",
      "\u001b[1;37mBatch loss 3 : 14.023735046386719\n",
      "\n",
      "\u001b[1;37mBatch loss 4 : 12.899801254272461\n",
      "\n",
      "\u001b[1;37mBatch loss 5 : 10.9633150100708\n",
      "\n",
      "\u001b[1;37mBatch loss 6 : 9.628517150878906\n",
      "\n",
      "\u001b[1;37mBatch loss 7 : 8.51556396484375\n",
      "\n",
      "\u001b[1;37mBatch loss 8 : 7.96274471282959\n",
      "\n",
      "\u001b[1;37mBatch loss 9 : 6.252326011657715\n",
      "\n",
      "\u001b[1;37mBatch loss 10 : 5.716900825500488\n",
      "\n",
      "\u001b[1;37mBatch loss 11 : 5.511084079742432\n",
      "\n",
      "\u001b[1;37mBatch loss 12 : 5.229101657867432\n",
      "\n",
      "\u001b[1;37mBatch loss 13 : 4.8089823722839355\n",
      "\n",
      "\u001b[1;37mBatch loss 14 : 4.398077487945557\n",
      "\n",
      "\u001b[1;37mBatch loss 15 : 4.0155439376831055\n",
      "\n",
      "\u001b[1;37mBatch loss 16 : 4.608884334564209\n",
      "\n",
      "\u001b[1;37mBatch loss 17 : 3.778088331222534\n",
      "\n",
      "\u001b[1;37mBatch loss 18 : 3.1733648777008057\n",
      "\n",
      "\u001b[1;37mBatch loss 19 : 3.6697213649749756\n",
      "\n",
      "\u001b[1;37mBatch loss 20 : 3.3979556560516357\n",
      "\n",
      "\u001b[1;37mBatch loss 21 : 4.1105055809021\n",
      "\n",
      "\u001b[1;37mBatch loss 22 : 2.7609527111053467\n",
      "\n",
      "\u001b[1;37mBatch loss 23 : 2.822329044342041\n",
      "\n",
      "\u001b[1;37mBatch loss 24 : 3.497847318649292\n",
      "\n",
      "\u001b[1;37mBatch loss 25 : 3.173666477203369\n",
      "\n",
      "\u001b[1;37mBatch loss 26 : 3.339343309402466\n",
      "\n",
      "\u001b[1;37mBatch loss 27 : 2.795927047729492\n",
      "\n",
      "\u001b[1;37mBatch loss 28 : 2.7533349990844727\n",
      "\n",
      "\u001b[1;37mBatch loss 29 : 2.9161014556884766\n",
      "\n",
      "\u001b[1;37mBatch loss 30 : 3.147975206375122\n",
      "\n",
      "\u001b[1;37mBatch loss 31 : 2.4897196292877197\n",
      "\n",
      "\u001b[1;37mBatch loss 32 : 2.823526382446289\n",
      "\n",
      "\u001b[1;37mBatch loss 33 : 2.6090004444122314\n",
      "\n",
      "\u001b[1;37mBatch loss 34 : 2.3172061443328857\n",
      "\n",
      "\u001b[1;37mBatch loss 35 : 2.378152370452881\n",
      "\n",
      "\u001b[1;37mBatch loss 36 : 2.145321846008301\n",
      "\n",
      "\u001b[1;37mBatch loss 37 : 2.3666601181030273\n",
      "\n",
      "\u001b[1;37mBatch loss 38 : 2.5385444164276123\n",
      "\n",
      "\u001b[1;37mBatch loss 39 : 2.7443583011627197\n",
      "\n",
      "\u001b[1;37mBatch loss 40 : 2.0066022872924805\n",
      "\n",
      "\u001b[1;37mBatch loss 41 : 1.7571024894714355\n",
      "\n",
      "\u001b[1;37mBatch loss 42 : 3.1038732528686523\n",
      "\n",
      "\u001b[1;37mBatch loss 43 : 2.2523176670074463\n",
      "\n",
      "\u001b[1;37mBatch loss 44 : 1.8127788305282593\n",
      "\n",
      "\u001b[1;37mBatch loss 45 : 1.7831417322158813\n",
      "\n",
      "\u001b[1;37mBatch loss 46 : 1.8651570081710815\n",
      "\n",
      "\u001b[1;37mBatch loss 47 : 2.4535863399505615\n",
      "\n",
      "\u001b[1;37mBatch loss 48 : 1.817555546760559\n",
      "\n",
      "\u001b[1;37mBatch loss 49 : 2.0426108837127686\n",
      "\n",
      "\u001b[1;37mBatch loss 50 : 1.8780192136764526\n",
      "\n",
      "\u001b[1;37mBatch loss 51 : 1.9138481616973877\n",
      "\n",
      "\u001b[1;37mBatch loss 52 : 1.5680853128433228\n",
      "\n",
      "\u001b[1;37mBatch loss 53 : 1.4719908237457275\n",
      "\n",
      "\u001b[1;37mBatch loss 54 : 1.969879150390625\n",
      "\n",
      "\u001b[1;37mBatch loss 55 : 1.7515110969543457\n",
      "\n",
      "\u001b[1;37mBatch loss 56 : 1.968217134475708\n",
      "\n",
      "\u001b[1;37mBatch loss 57 : 1.9628545045852661\n",
      "\n",
      "\u001b[1;37mBatch loss 58 : 1.693697214126587\n",
      "\n",
      "\u001b[1;37mBatch loss 59 : 1.7836192846298218\n"
     ]
    }
   ],
   "source": [
    "# Entrainement\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    EPOCHS = 1\n",
    "    LR = 1e-4\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, eps=5e-8)\n",
    "    module = train_loop(module=model,\n",
    "                        EPOCHS=EPOCHS, \n",
    "                        train_dataset=train_dataloaded, \n",
    "                        val_dataset=val_dataloaded,\n",
    "                        optimizer=optimizer)\n",
    "    predictions, true_targets = evaluate(module, \n",
    "                                         test_dataloaded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'active.all.allocated': 2189543, 'active.all.current': 759, 'active.all.freed': 2188784, 'active.all.peak': 1024, 'active.large_pool.allocated': 1020003, 'active.large_pool.current': 277, 'active.large_pool.freed': 1019726, 'active.large_pool.peak': 381, 'active.small_pool.allocated': 1169540, 'active.small_pool.current': 482, 'active.small_pool.freed': 1169058, 'active.small_pool.peak': 721, 'active_bytes.all.allocated': 8415742742016, 'active_bytes.all.current': 10911057408, 'active_bytes.all.freed': 8404831684608, 'active_bytes.all.peak': 10917021184, 'active_bytes.large_pool.allocated': 8239346608128, 'active_bytes.large_pool.current': 10908502528, 'active_bytes.large_pool.freed': 8228438105600, 'active_bytes.large_pool.peak': 10913417728, 'active_bytes.small_pool.allocated': 176396133888, 'active_bytes.small_pool.current': 2554880, 'active_bytes.small_pool.freed': 176393579008, 'active_bytes.small_pool.peak': 13091328, 'allocated_bytes.all.allocated': 8415742742016, 'allocated_bytes.all.current': 10911057408, 'allocated_bytes.all.freed': 8404831684608, 'allocated_bytes.all.peak': 10917021184, 'allocated_bytes.large_pool.allocated': 8239346608128, 'allocated_bytes.large_pool.current': 10908502528, 'allocated_bytes.large_pool.freed': 8228438105600, 'allocated_bytes.large_pool.peak': 10913417728, 'allocated_bytes.small_pool.allocated': 176396133888, 'allocated_bytes.small_pool.current': 2554880, 'allocated_bytes.small_pool.freed': 176393579008, 'allocated_bytes.small_pool.peak': 13091328, 'allocation.all.allocated': 2189543, 'allocation.all.current': 759, 'allocation.all.freed': 2188784, 'allocation.all.peak': 1024, 'allocation.large_pool.allocated': 1020003, 'allocation.large_pool.current': 277, 'allocation.large_pool.freed': 1019726, 'allocation.large_pool.peak': 381, 'allocation.small_pool.allocated': 1169540, 'allocation.small_pool.current': 482, 'allocation.small_pool.freed': 1169058, 'allocation.small_pool.peak': 721, 'inactive_split.all.allocated': 923814, 'inactive_split.all.current': 109, 'inactive_split.all.freed': 923705, 'inactive_split.all.peak': 112, 'inactive_split.large_pool.allocated': 596745, 'inactive_split.large_pool.current': 107, 'inactive_split.large_pool.freed': 596638, 'inactive_split.large_pool.peak': 107, 'inactive_split.small_pool.allocated': 327069, 'inactive_split.small_pool.current': 2, 'inactive_split.small_pool.freed': 327067, 'inactive_split.small_pool.peak': 35, 'inactive_split_bytes.all.allocated': 7659926622208, 'inactive_split_bytes.all.current': 352745984, 'inactive_split_bytes.all.freed': 7659573876224, 'inactive_split_bytes.all.peak': 461697024, 'inactive_split_bytes.large_pool.allocated': 7477676526592, 'inactive_split_bytes.large_pool.current': 351106560, 'inactive_split_bytes.large_pool.freed': 7477325420032, 'inactive_split_bytes.large_pool.peak': 455366144, 'inactive_split_bytes.small_pool.allocated': 182250095616, 'inactive_split_bytes.small_pool.current': 1639424, 'inactive_split_bytes.small_pool.freed': 182248456192, 'inactive_split_bytes.small_pool.peak': 6462464, 'max_split_size': -1, 'num_alloc_retries': 2, 'num_device_alloc': 141, 'num_device_free': 34, 'num_ooms': 1, 'num_sync_all_streams': 2, 'oversize_allocations.allocated': 0, 'oversize_allocations.current': 0, 'oversize_allocations.freed': 0, 'oversize_allocations.peak': 0, 'oversize_segments.allocated': 0, 'oversize_segments.current': 0, 'oversize_segments.freed': 0, 'oversize_segments.peak': 0, 'requested_bytes.all.allocated': 8378264917645, 'requested_bytes.all.current': 10908486520, 'requested_bytes.all.freed': 8367356431125, 'requested_bytes.all.peak': 10914450296, 'requested_bytes.large_pool.allocated': 8202114798080, 'requested_bytes.large_pool.current': 10905956864, 'requested_bytes.large_pool.freed': 8191208841216, 'requested_bytes.large_pool.peak': 10910872064, 'requested_bytes.small_pool.allocated': 176150119565, 'requested_bytes.small_pool.current': 2529656, 'requested_bytes.small_pool.freed': 176147589909, 'requested_bytes.small_pool.peak': 13077692, 'reserved_bytes.all.allocated': 11863588864, 'reserved_bytes.all.current': 11263803392, 'reserved_bytes.all.freed': 599785472, 'reserved_bytes.all.peak': 11270094848, 'reserved_bytes.large_pool.allocated': 11846811648, 'reserved_bytes.large_pool.current': 11259609088, 'reserved_bytes.large_pool.freed': 587202560, 'reserved_bytes.large_pool.peak': 11259609088, 'reserved_bytes.small_pool.allocated': 16777216, 'reserved_bytes.small_pool.current': 4194304, 'reserved_bytes.small_pool.freed': 12582912, 'reserved_bytes.small_pool.peak': 14680064, 'segment.all.allocated': 141, 'segment.all.current': 107, 'segment.all.freed': 34, 'segment.all.peak': 137, 'segment.large_pool.allocated': 133, 'segment.large_pool.current': 105, 'segment.large_pool.freed': 28, 'segment.large_pool.peak': 130, 'segment.small_pool.allocated': 8, 'segment.small_pool.current': 2, 'segment.small_pool.freed': 6, 'segment.small_pool.peak': 7})\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_stats())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs.input_ids.max())\n",
    "print(inputs.input_ids.min())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_IODAA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
